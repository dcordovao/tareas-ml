{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-393/578 Máquinas de Aprendizaje - 2019-1 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 3  </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "* Manipulaciones en numpy\n",
    "* Arboles de clasificación y regresión\n",
    "* Algunas Redes neuronales básicas\n",
    "* Ensamblados, Adaboost y Random Forest\n",
    "* Nociones de clases desbalanceadas\n",
    "\n",
    "\n",
    "**Formalidades**  \n",
    "* Equipos de trabajo de 2 personas (*Ambos estudiantes deben estar preparados para presentar la tarea el día de la entrega*)\n",
    "* El entregable debe ser un _Jupyter Notebook_ incluyendo los códigos utilizados, los resultados, los gráficos realizados y comentarios. Debe seguir una estructura similar a un informe (se debe introducir los problemas a trabajar, presentar los resultados y discutirlos). Si lo prefiere puede entregar un _Jupyter Notebook_ por pregunta o uno por toda la tarea, con tal de que todos los entregables esten bien identificados y se encuentren en el mismo repositorio de _Github_.\n",
    "* Se debe preparar una presentación del trabajo realizado y sus hallazgos. El presentador será elegido aleatoriamente y deberá apoyarse en el _Jupyter Notebook_ que entregarán. \n",
    "* Formato de entrega: envı́o de link del repositorio *privado* en _Github_, al correo electrónico del ayudante (*<alvaro.valderrama.13@sansano.usm.cl>*), en copia al profesor (*<cvalle@inf.utfsm.cl>*). Especificar el siguiente asunto: [INF393/578-2019 Tarea 3]. Invitar como colaborador al usuario de github \"avalderr\" para poder acceder al repositorio.\n",
    "* Fecha de entrega y presentaciones: 13 de Septiembre. Hora límite de entrega: 23:50. Cualquier _commit_ luego de la hora límite no será evaluado. Se realizará descuento por atrasos en envío del mail. \n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en tres partes:\n",
    "\n",
    "[1.](#primero) Regresión para ubicación espacial  \n",
    "[2.](#segundo) Clasificación con clases desbalanceadas    \n",
    "[3.](#tercero) Clasificación en texto   \n",
    "\n",
    "La tarea tiene ejemplos de códigos con los cuales pueden guiarse en gran parte, sin embargo solo son guias y pueden ser creativos al momento de resolver la tarea. Soluciones creativas o elegantes serán valoradas. También en algunas ocaciones se hacen elecciones arbitrarias, ustedes pueden realizar otras elecciones con tal de que haya una pequeña justificación de por qué su elección es mejor o equivalente.\n",
    "Recuerden intercalar su código con comentarios y con celdas _Markdown_ con los comentarios de la pregunta y con cualquier analisis, fórmula (en $ \\LaTeX $) o explicación que les parezca relevante para justificar sus procedimientos. \n",
    "Noten que en general cuando se les pide elegir algo o proponer algo no se evaluará mucho la elección en si, en cambio la argumentación detrás de la elección será lo más ponderado.\n",
    "Si algun modelo se demora demasiado en correr en su maquina, no olvide que puede correr _Jupyter Notebooks_ en _Collab_ de Google, esto puede ser relevante para las maquinas más lentas al momento de realizar exploraciones con _K-folds_ por ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"segundo\"></a>\n",
    "## 2. Clasificación con clases desbalanceadas\n",
    "\n",
    "En las tareas de clasificación supervisada, buscamos que mediante los ejemplos etiquetados la maquina pueda aprender los atributos inerentes a las distintas clases. Sin embargo, en muchos casos reales de clasificación, la cantidad de ejemplos de cada clase son muy dispares, en cuyo caso hablamos de clases desbalanceadas. Si uno no aplica estrategias para compensar este problema, la maquina aprenderá muy bien las caracteristicas de la clase más representada pero no logrará extraer información generalizable de la clase menos representada. Además, debemos tener cuidado al momento de interpretar las distintas métricas a las cuales tenemos acceso, pues debemos tomar en cuenta el balance de las clases y la naturaleza del problema para evaluar realmente que tan bueno es el desempeño. \n",
    "\n",
    "\n",
    "\n",
    "Para esta parte de la tarea utilizaremos el siguiente _dataset_ publicado en Kaggle: https://www.kaggle.com/mlg-ulb/creditcardfraud. Este conjunto de datos contiene unos 285000 ejemplos de transacciones con tarjetas de crédito reales, realizadas en 2013 por clientes europeos. Los datos son totalmente anónimos y son el resultado de un PCA a partir de los datos originales excepto por las columnas `Time` con el tiempo en segundos desde la primera transacción, `Amount` con el monto de la transacción y `Class` que indica si la transacción es fraudulenta o no. La tarea en cuestión consiste en lograr predecir cuando una transacción es fraudulenta o no automaticamente, para así poder detenerla antes de que se termine. Sin embargo, por la naturaleza de las transacciones bancarias, este problema es desbalanceado, de hecho de los 285000 transacciones registradas, solo 492 son fraudulentas! A lo largo de esta pregunta pondremos en evidencia los problemas que se originan de este desbalance de clases y trataremos de dar luces a algunas herramientas que nos permitan sortear esos problemas y como medir realmente el desempeño en esta clase de problemas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a Carga de datos\n",
    "Descargue los datos y cárguelos usando pandas. Haga una exploración rápida de los datos, cuantos datos hay, como se reparten sus valores.\n",
    "\n",
    "Grafique la matriz de correlación, a primera vista parece relevante mantener la columna `Time`? En su opinión, conociendo la naturaleza del problema le parece relevante esa información para predecir el _target_?\n",
    "\n",
    "Cuantos ejemplos hay de cada clase? Son las clases desbalanceadas efectivamente? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Time            V1            V2            V3            V4  \\\n",
      "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean    94813.859575  1.165980e-15  3.416908e-16 -1.373150e-15  2.086869e-15   \n",
      "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
      "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
      "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
      "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
      "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
      "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
      "\n",
      "                 V5            V6            V7            V8            V9  \\\n",
      "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean   9.604066e-16  1.490107e-15 -5.556467e-16  1.177556e-16 -2.406455e-15   \n",
      "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
      "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
      "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
      "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
      "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
      "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
      "\n",
      "       ...           V21           V22           V23           V24  \\\n",
      "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean   ...  1.656562e-16 -3.444850e-16  2.578648e-16  4.471968e-15   \n",
      "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
      "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
      "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
      "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
      "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
      "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
      "\n",
      "                V25           V26           V27           V28         Amount  \\\n",
      "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
      "mean   5.340915e-16  1.687098e-15 -3.666453e-16 -1.220404e-16      88.349619   \n",
      "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
      "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
      "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
      "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
      "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
      "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
      "\n",
      "               Class  \n",
      "count  284807.000000  \n",
      "mean        0.001727  \n",
      "std         0.041527  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data/data_pregunta2/creditcard.csv')\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff99f4c00f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[lambda x: x.Class != 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284315, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[lambda x: x.Class == 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.b Ligero preprocesamiento\n",
    "\n",
    "* Escale la columna `Amount`. Por qué es aconsejable realizar esto? Le parece necesario realizarlo en el resto de las columnas? \n",
    "\n",
    "* Separe los atributos del _target_.\n",
    "\n",
    "* Separe luego los datos en _Training set_ y _Validation set_, con un 20% de los datos como validación y el resto como _train_. Asegurese que se mantienen las proporciones de ejemplos de cada clase en ambos sets. \n",
    "\n",
    "* Qué ocurriría si por ejemplo todos los ejemplos de la clase 1 quedaran en el _validation set_, que haría cualquier máquina de aprendizaje al aprender solo con la clase 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/.local/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/home/diego/.local/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[df.columns[1:-1]]\n",
    "y = df.Class\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler_amount = StandardScaler()\n",
    "\n",
    "scaler_amount.fit(X_train['Amount'].values.reshape(-1,1))\n",
    "\n",
    "X_train['Amount'] = scaler_amount.transform(X_train['Amount'].values.reshape(-1,1))\n",
    "X_test['Amount'] = scaler_amount.transform(X_test['Amount'].values.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.c Regresor logístico\n",
    "\n",
    "Entrene un regresor logístico con los datos obtenidos de la pregunta anterior y calcule su desempeño (_score_ por ahora) sobre los datos de validación. A priori le parece un buen desempeño? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "score_train = r2_score(logistic_model.predict(X_train), y_train)\n",
    "score_test = r2_score(logistic_model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SCORE:  0.3576363540773725\n",
      "TEST SCORE:  0.2144882588104553\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING SCORE: \", score_train)\n",
    "print(\"TEST SCORE: \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.d _Always_ 0\n",
    "\n",
    "Suponga un modelo le entrega como resultado en el conjunto de validación el siguiente `y_pred`. ¿Qué está haciendo este predictor? ¿Qué _score_ obtendría tal modelo sobre el conjunto de validación? ¿Le parece que el modelo tenga un buen desempeño? Concluya sobre la calidad del _accuracy_ que obtenemos con `.score` para evaluar el desempeño de estos modelos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.np.zeros(y_val.shape)\n",
    "\n",
    "# . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.e Matriz de confusión\n",
    "\n",
    "Investigue un poco sobre los valores que conforman la matriz de confusión o _confusion matrix_. Comente sobre la significancia de los distintos valores para el problema en cuestión. \n",
    "\n",
    "Escriba una función que a partir de un modelo o de los valores predecidos por un modelo, grafique la matriz de confusión. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puede usar libreria seaborn para realizar facilmente heatmaps anotados: \n",
    "import seaborn as sns\n",
    "# . . .\n",
    "sns.heatmap( confusion_matrix(y_test, model.predict(X_test))/len(X_test),cmap='winter', annot=True)    \n",
    "# . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafique la matriz de confusión para la regresión logística realizada en el punto c y para los valores `y_pred` del punto d. Le parecen parecidos ahora ambos modelos? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.f Curva ROC\n",
    "La curva ROC tiene bastante utilidad para evaluar la calidad de distintos modelos en estos casos. Investigue un poco sobre su significado para poder interpretarla correctamente y luego escriba una función que reciba un modelo entrenado y la grafíque. \n",
    "\n",
    "Note que `sklearn` trae implementado una función que entrega los puntos de la curva ROC, note eso sí que debe entregarle las probabilidades usando el método `predict_proba` del modelo entrenado. \n",
    "\n",
    "Para evaluar distintos modelos utilizará bastante las curvas ROC y la matriz de confusión, por lo que sería recomendable escribir una función que reciba un modelo y datos y realice tanto la curva ROC como la matriz de confusión, aunque escribir tal función no es requisito. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_ts, model.predict_proba(x_ts)[:,1],pos_label=1)\n",
    "\n",
    "plt.plot(fpr, tpr, label=# . . . )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice la función definida para su modelo de regresión logística. Comente el gráfico obtenido. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.g Arbol de Clasificación\n",
    "Entrene un arbol de clasificación para tratar de resolver el problema. Pruebe unas cuantas profundidades máximas distintas y elija una. Si quiere puede modificar los otros hiperparámetros del modelo. \n",
    "\n",
    "Evalúe su desempeño respecto a los modelos lineales usando las métricas relevantes y compare su costo computacional. Discuta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(\n",
    "            criterion='gini',\n",
    "            max_depth=3\n",
    ")\n",
    "# . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.h _Undersampling_\n",
    "\n",
    "Considerando que la gran mayoría del aprendizaje se realiza en los ejemplos no fraudulentos, una aproximación para tratar de mejorar el desempeño de los modelos entrenados es simplemente reducir la cantidad de ejemplos de una clase para obtener nuevos conjuntos de datos con clases más balanceadas. Así, el aprendizaje se realiza de manera más balanceada entre ambas clases y se logran extraer mejor los atributos de cada clase. \n",
    "\n",
    "Complete la siguiente función para que realice un _undersampling_ de la clase 0 para obtener una proporción en el nuevo conjundo de datos de `times` veces el numero de transacciones normales frente a fraudulentas. Comente sobre la decisión del parámetro `replace` de la función `numpy.random.choice`. \n",
    "\n",
    "\n",
    "Note que la función debe recibir los datos de entrenamiento. Se pide que retorne un conjunto de datos de entrenamiento _undersampled_ para poder entrenar. Las validaciones deben realizarse sobre el conjunto de Validación original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(x_tr, y_tr, times = 10):\n",
    "    fraud_indices = y_tr.index[y_tr == 1]\n",
    "    normal_indices = # . . .\n",
    "\n",
    "    Count_Fraud_transacation = # . . .\n",
    "    \n",
    "    undersample_index = pd.np.concatenate([\n",
    "        pd.np.random.choice(\n",
    "            normal_indices,\n",
    "            Count_Fraud_transaction * #something,\n",
    "            replace = # True or False?)\n",
    "                            ),\n",
    "        fraud_indices])\n",
    "    \n",
    "    undersample_index = pd.np.concatenate([fraud_indices,Normal_indices_undersample])\n",
    "    undersampled_x = x_tr.loc[undersample_index]\n",
    "    # . . .\n",
    "    return undersampled_x, undersampled_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.i Entrenar con _Undersampling_\n",
    "\n",
    "Pruebe distintos valores para el parámetro `times` y evalue si hay diferencias significativas en la curva ROC y la matriz de confución para el mismo árbol de clasificación entrenado anteriormente. Evidentemente el número de ejemplos de entrenamiento cambia a medida cambia el parámetro `times`, sin embargo nuestro interés no es que tan bien se comporta el modelo sobre los datos de entrenamiento si no sobre los de validación, los cuales deben ser constantes a lo largo del análisis.\n",
    "\n",
    "¿Como se comparan estos modelos con el modelo con todos los datos (recuerde que las comparaciones deben hacerse calculando el desempeño sobre el conjunto de validación completo con el modelo una vez entrenado)? ¿Ve alguna ventaja en el uso de _undersampling_ frente al uso de todos los datos? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.j _Oversampling_\n",
    "\n",
    "Otra aproximación para resolver el problema de las clases desbalanceadas es hacer _oversampling_. A partir de una muestra relativamente pequeña de ejemplos, en este caso de los casos de fraude, se busca crear un conjunto de datos más grande similar al inicial, que permita al modelo aprender las caracteristicas de esa clase, buscando nuevamente obtener clases más balanceadas que originalmente, pero esta vez sin reducir la cantidad de ejemplos. Esta aproximación tiene la ventaja que no reduce la cantidad de ejemplos pero trae la complicación de decidir cómo se van a crear los datos nuevos.\n",
    "\n",
    "Dos aproximaciones bastante estandar son SMOTE y ADASYN. Investigue un poco que hace SMOTE y que diferencia implemente ADASYN. Por qué cree puede ser deseable buscar que los datos sintéticos no sean linealmente dependientes de los datos originales? \n",
    "\n",
    "Elija alguno de los dos métodos e impelementelo con el árbol entrenado previamente. Comente sobre el desempeño de tal modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install  imbalanced-learn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "ada = ADASYN()\n",
    "# . . .\n",
    "x_tr_r, y_tr_r  = smo.fit_resample(x_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que tanto SMOTE como ADASYN tienen muchos parámetros que podrían afectar la calidad de los datos generados. No se requiere que elijan tales parametros (los por defecto bastan), pero se valorará un pequeño comentario sobre los parámetros de los métodos y qué representan en la heuristica utilizada. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.k Redes neuronales _Feed Forward_ \n",
    "\n",
    "Por útimo, probaremos utilizar una red neuronal densa sobre los datos aumentados. Las Redes Neuronales son una herramienta muy poderosa pero comparativamente costosa frente a otros modelos. Entrenar una red neuronal puede resultar muy costos computacionalmente, por su gran numero de parámetros entrenables y por el caracter iterativo de su entrenamiento. Además, el gran numero de parámetros hace que las redes neuronales sean particularmente sensibles al _overfitting_, por lo cual suele ser necesario tener grandes cantidades de datos para poder entrenar una red neuronal obteniendo desempeños que justifiquen su costo adicional.\n",
    "\n",
    "Por esto, entrenaremos la red neuronal sobre los datos aumentados. Básese en el código siguiente para crea la red neuronal. Explique los parámetros que se pasan en cada etapa de su creación, para esto puede leer la documentación de keras. Finalente, entrene \"completamente\" la red, es decir hasta que se estanque el error de validación o comience a aumentar. ¿Cómo se compara la red frente a otros modelos, tanto en desempeño como en costo? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='sgd',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(x_tr.values,y_tr.values, epochs=20, validation_data=(X_test,y_test))\n",
    "\n",
    "# note that history.history gives you the values of tr and val errors and accuracies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
